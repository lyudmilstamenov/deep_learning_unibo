{"cells":[{"cell_type":"markdown","metadata":{"id":"ElNaMbLnRdHR"},"source":["# Sentence Reconstruction"]},{"cell_type":"markdown","metadata":{"id":"oXr4iGUGRms8"},"source":["The purpose of this project is to take in input a sequence of words corresponding to a random permutation of a given english sentence, and reconstruct the original sentence.\n","\n","The otuput can be either produced in a single shot, or through an iterative (autoregressive) loop generating a single token at a time.\n","\n","\n","CONSTRAINTS:\n","* No pretrained model can be used.\n","* The neural network models should have less the 20M parameters.\n","* No postprocessing should be done (e.g. no beamsearch)\n","* You cannot use additional training data.\n","\n","\n","BONUS PARAMETERS:\n","\n","A bonus of 0-2 points will be attributed to incentivate the adoption of models with a low number of parameters."]},{"cell_type":"markdown","metadata":{"id":"iQ8k-L-WUK7l"},"source":["# Dataset\n","\n","The dataset is composed by sentences taken from the generics_kb dataset of hugging face. We restricted the vocabolary to the 10K most frequent words, and only took sentences making use of this vocabulary."]},{"cell_type":"code","execution_count":133,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-06-08T14:33:19.437425Z","iopub.status.busy":"2024-06-08T14:33:19.437020Z","iopub.status.idle":"2024-06-08T14:33:21.670118Z","shell.execute_reply":"2024-06-08T14:33:21.668899Z","shell.execute_reply.started":"2024-06-08T14:33:19.437391Z"},"id":"nJ02vehGYySk","outputId":"084cf1b6-7407-4572-c408-e88de7449980","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  pid, fd = os.forkpty()\n"]},{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.19.2)\n","^C\n","\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["!pip install datasets"]},{"cell_type":"markdown","metadata":{"id":"807Wk-ir_bDU"},"source":["Download the dataset"]},{"cell_type":"code","execution_count":134,"metadata":{"execution":{"iopub.execute_input":"2024-06-08T14:33:21.672760Z","iopub.status.busy":"2024-06-08T14:33:21.672422Z","iopub.status.idle":"2024-06-08T14:33:22.505475Z","shell.execute_reply":"2024-06-08T14:33:22.504711Z","shell.execute_reply.started":"2024-06-08T14:33:21.672727Z"},"id":"_WjtqA8TrHcS","trusted":true},"outputs":[],"source":["from datasets import load_dataset\n","from keras.layers import TextVectorization\n","import tensorflow as tf\n","import numpy as np\n","np.random.seed(42)\n","ds = load_dataset('generics_kb',trust_remote_code=True)['train']"]},{"cell_type":"markdown","metadata":{"id":"lAVLfsdc_ej5"},"source":["Filter row with length greater than 8.\n"]},{"cell_type":"code","execution_count":135,"metadata":{"execution":{"iopub.execute_input":"2024-06-08T14:33:22.507070Z","iopub.status.busy":"2024-06-08T14:33:22.506820Z","iopub.status.idle":"2024-06-08T14:33:25.943580Z","shell.execute_reply":"2024-06-08T14:33:25.937129Z","shell.execute_reply.started":"2024-06-08T14:33:22.507047Z"},"id":"iznq8xGNt2Zr","trusted":true},"outputs":[{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[135], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m ds \u001b[38;5;241m=\u001b[39m ds\u001b[38;5;241m.\u001b[39mfilter(\u001b[38;5;28;01mlambda\u001b[39;00m row: \u001b[38;5;28mlen\u001b[39m(row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneric_sentence\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m8\u001b[39m )\n\u001b[0;32m----> 2\u001b[0m corpus \u001b[38;5;241m=\u001b[39m [ \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<start> \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeneric_sentence\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m <comma>\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m <end>\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m ds ]\n\u001b[1;32m      3\u001b[0m corpus \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(corpus)\n","Cell \u001b[0;32mIn[135], line 2\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m ds \u001b[38;5;241m=\u001b[39m ds\u001b[38;5;241m.\u001b[39mfilter(\u001b[38;5;28;01mlambda\u001b[39;00m row: \u001b[38;5;28mlen\u001b[39m(row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneric_sentence\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m8\u001b[39m )\n\u001b[0;32m----> 2\u001b[0m corpus \u001b[38;5;241m=\u001b[39m [ \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<start> \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeneric_sentence\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m <comma>\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m <end>\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m ds ]\n\u001b[1;32m      3\u001b[0m corpus \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(corpus)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/arrow_dataset.py:2450\u001b[0m, in \u001b[0;36mDataset.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2448\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2449\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_rows):\n\u001b[0;32m-> 2450\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2451\u001b[0m \u001b[43m            \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2452\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/arrow_dataset.py:2845\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[0;34m(self, key, **kwargs)\u001b[0m\n\u001b[1;32m   2843\u001b[0m format_kwargs \u001b[38;5;241m=\u001b[39m format_kwargs \u001b[38;5;28;01mif\u001b[39;00m format_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m   2844\u001b[0m formatter \u001b[38;5;241m=\u001b[39m get_formatter(format_type, features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mfeatures, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_kwargs)\n\u001b[0;32m-> 2845\u001b[0m pa_subtable \u001b[38;5;241m=\u001b[39m \u001b[43mquery_table\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2846\u001b[0m formatted_output \u001b[38;5;241m=\u001b[39m format_table(\n\u001b[1;32m   2847\u001b[0m     pa_subtable, key, formatter\u001b[38;5;241m=\u001b[39mformatter, format_columns\u001b[38;5;241m=\u001b[39mformat_columns, output_all_columns\u001b[38;5;241m=\u001b[39moutput_all_columns\n\u001b[1;32m   2848\u001b[0m )\n\u001b[1;32m   2849\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m formatted_output\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/formatting/formatting.py:592\u001b[0m, in \u001b[0;36mquery_table\u001b[0;34m(table, key, indices)\u001b[0m\n\u001b[1;32m    590\u001b[0m     pa_subtable \u001b[38;5;241m=\u001b[39m _query_table(table, key)\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 592\u001b[0m     pa_subtable \u001b[38;5;241m=\u001b[39m \u001b[43m_query_table_with_indices_mapping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pa_subtable\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/formatting/formatting.py:61\u001b[0m, in \u001b[0;36m_query_table_with_indices_mapping\u001b[0;34m(table, key, indices)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;124;03mQuery a pyarrow Table to extract the subtable that correspond to the given key.\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;124;03mThe :obj:`indices` parameter corresponds to the indices mapping in case we cant to take into\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;124;03maccount a shuffling or an indices selection for example.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;124;03mThe indices table must contain one column named \"indices\" of type uint64.\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m---> 61\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[43mindices\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfast_slice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_rows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_py\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _query_table(table, key)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mslice\u001b[39m):\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["ds = ds.filter(lambda row: len(row[\"generic_sentence\"].split(\" \")) > 8 )\n","corpus = [ '<start> ' + row['generic_sentence'].replace(\",\",\" <comma>\") + ' <end>' for row in ds ]\n","corpus = np.array(corpus)\n"]},{"cell_type":"markdown","metadata":{"id":"FyYpXLCF_ldR"},"source":["Create a tokenizer and Detokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-08T14:33:25.944488Z","iopub.status.idle":"2024-06-08T14:33:25.944855Z","shell.execute_reply":"2024-06-08T14:33:25.944697Z","shell.execute_reply.started":"2024-06-08T14:33:25.944682Z"},"id":"T-bE2JpVbU9E","trusted":true},"outputs":[],"source":["tokenizer=TextVectorization( max_tokens=10000, standardize=\"lower_and_strip_punctuation\", encoding=\"utf-8\",) #con il max prende le piu frequenti. ordina i token del vocab dal piu frequente al meno frequente\n","tokenizer.adapt(corpus)\n","\n","class TextDetokenizer:\n","    def __init__(self, vectorize_layer):\n","        self.vectorize_layer = vectorize_layer\n","        vocab = self.vectorize_layer.get_vocabulary()\n","        self.index_to_word = {index: word for index, word in enumerate(vocab)}\n","\n","    def __detokenize_tokens(self, tokens):\n","        def check_token(t):\n","          if t == 3:\n","            s=\"<start>\"\n","          elif t == 2:\n","            s=\"<end>\"\n","          elif t == 7:\n","            s=\"<comma>\"\n","          else:\n","            s=self.index_to_word.get(t, '[UNK]')\n","          return s\n","\n","        return ' '.join([ check_token(token) for token in tokens if token != 0])\n","\n","    def __call__(self, batch_tokens):\n","       return [self.__detokenize_tokens(tokens) for tokens in batch_tokens]\n","\n","\n","detokenizer = TextDetokenizer( tokenizer )\n","sentences = tokenizer( corpus ).numpy()"]},{"cell_type":"markdown","metadata":{"id":"lZ64sns1_pSK"},"source":["Remove from corpus the sentences where any unknow word appears"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-08T14:33:25.945901Z","iopub.status.idle":"2024-06-08T14:33:25.946244Z","shell.execute_reply":"2024-06-08T14:33:25.946094Z","shell.execute_reply.started":"2024-06-08T14:33:25.946079Z"},"id":"2LPQtryQz5wh","trusted":true},"outputs":[],"source":["mask = np.sum( (sentences==1), axis=1) >= 1\n","original_data = np.delete( sentences, mask , axis=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-06-08T14:33:25.947214Z","iopub.status.idle":"2024-06-08T14:33:25.947677Z","shell.execute_reply":"2024-06-08T14:33:25.947459Z","shell.execute_reply.started":"2024-06-08T14:33:25.947439Z"},"id":"qYfOscVk7U0r","outputId":"6bde9ac5-b585-42cc-ec5d-9e970d2160f2","trusted":true},"outputs":[],"source":["original_data.shape"]},{"cell_type":"markdown","metadata":{"id":"5puiiQ2D_uxa"},"source":["Shuffle the sentences"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-08T14:33:25.948949Z","iopub.status.idle":"2024-06-08T14:33:25.949310Z","shell.execute_reply":"2024-06-08T14:33:25.949138Z","shell.execute_reply.started":"2024-06-08T14:33:25.949123Z"},"id":"lSxaLztEQBg8","trusted":true},"outputs":[],"source":["def extract_full_data(generator):\n","    x_list = []\n","    y_list = []\n","    for i in range(len(generator)):\n","        x_batch, y_batch = generator[i]\n","        x_list.append(x_batch)\n","        y_list.append(y_batch)\n","    x = np.concatenate(x_list, axis=0)\n","    y = np.concatenate(y_list, axis=0)\n","    return x, y"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-08T14:33:25.951150Z","iopub.status.idle":"2024-06-08T14:33:25.951654Z","shell.execute_reply":"2024-06-08T14:33:25.951421Z","shell.execute_reply.started":"2024-06-08T14:33:25.951401Z"},"id":"1ZXLkWB6od0R","trusted":true},"outputs":[],"source":["from tensorflow.keras.utils import Sequence\n","\n","class DataGenerator(Sequence):\n","    def __init__(self, data, batch_size=32, shuffle=True, seed=42):\n","        self.data = data\n","        self.batch_size = batch_size\n","        self.shuffle = shuffle\n","        self.seed = seed\n","        self.on_epoch_end()\n","\n","\n","    def __len__(self):\n","        return int(np.floor(len(self.data) / self.batch_size))\n","\n","    def __getitem__(self, index):\n","        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n","\n","        data_batch = np.array([self.data[k] for k in indexes])\n","        #copy of ordered sequences\n","        result = np.copy(data_batch)\n","        #shuffle only the relevant positions for each batch\n","        for i in range(data_batch.shape[0]):\n","          np.random.shuffle(data_batch[i,1:data_batch[i].argmin() - 1])\n","\n","        return data_batch , result\n","\n","    def on_epoch_end(self):\n","        self.indexes = np.arange(len(self.data))\n","        if self.shuffle:\n","            if self.seed is not None:\n","                np.random.seed(self.seed)\n","            np.random.shuffle(self.indexes)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-08T14:33:25.953151Z","iopub.status.idle":"2024-06-08T14:33:25.953499Z","shell.execute_reply":"2024-06-08T14:33:25.953348Z","shell.execute_reply.started":"2024-06-08T14:33:25.953333Z"},"id":"HUty97CTl3Zw","trusted":true},"outputs":[],"source":["# Make a random permutation of training and test set\n","np.random.seed(42)\n","# Shuffle the all data\n","shuffled_indices = np.random.permutation(len(original_data))\n","shuffled_data = original_data[shuffled_indices]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-08T14:33:25.954838Z","iopub.status.idle":"2024-06-08T14:33:25.955208Z","shell.execute_reply":"2024-06-08T14:33:25.955036Z","shell.execute_reply.started":"2024-06-08T14:33:25.955021Z"},"id":"uNlq1Khx1oH2","trusted":true},"outputs":[],"source":["train_generator = DataGenerator(shuffled_data[:220000])\n","test_generator = DataGenerator(shuffled_data[220000:])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-06-08T14:33:25.956223Z","iopub.status.idle":"2024-06-08T14:33:25.956616Z","shell.execute_reply":"2024-06-08T14:33:25.956462Z","shell.execute_reply.started":"2024-06-08T14:33:25.956448Z"},"id":"5yiFpF_9HFsG","outputId":"a419b678-de69-4b9d-d283-c81b419830a7","trusted":true},"outputs":[],"source":["x, y = test_generator.__getitem__(1)\n","x = detokenizer(x)\n","y = detokenizer(y)\n","\n","for i in range(7):\n","  print(\"original: \", y[i])\n","  print(\"shuffled: \", x[i])\n","  print(\"\\n\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-08T14:33:25.957702Z","iopub.status.idle":"2024-06-08T14:33:25.958028Z","shell.execute_reply":"2024-06-08T14:33:25.957880Z","shell.execute_reply.started":"2024-06-08T14:33:25.957865Z"},"id":"jXRPyCS2HH8z","trusted":true},"outputs":[],"source":["from difflib import SequenceMatcher\n","\n","def score(s,p):\n","  match = SequenceMatcher(None, s, p).find_longest_match()\n","  return (match.size/max(len(p),len(s)))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-06-08T14:33:25.959317Z","iopub.status.idle":"2024-06-08T14:33:25.959654Z","shell.execute_reply":"2024-06-08T14:33:25.959502Z","shell.execute_reply.started":"2024-06-08T14:33:25.959488Z"},"id":"A7kh_DTzHJJK","outputId":"17b19161-8c78-44e7-9753-2cd687836351","trusted":true},"outputs":[],"source":["original = \"at first henry wanted to be friends with the king of france\"\n","generated = \"henry wanted to be friends with king of france at the first\"\n","\n","print(\"your score is \",score(original,generated))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-06-08T14:33:25.960481Z","iopub.status.idle":"2024-06-08T14:33:25.960821Z","shell.execute_reply":"2024-06-08T14:33:25.960668Z","shell.execute_reply.started":"2024-06-08T14:33:25.960653Z"},"id":"AqK_VBMERIr5","outputId":"098c0630-928b-4750-b1b1-7392ebc67635","trusted":true},"outputs":[],"source":["x_train, y_train = extract_full_data(train_generator)\n","x_train.shape, y_train.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-06-08T14:33:25.962609Z","iopub.status.idle":"2024-06-08T14:33:25.962971Z","shell.execute_reply":"2024-06-08T14:33:25.962807Z","shell.execute_reply.started":"2024-06-08T14:33:25.962791Z"},"id":"Gp0_kxvBRJpL","outputId":"1f99ae8c-e8df-49db-ab9e-8fd6d7df3ada","trusted":true},"outputs":[],"source":["x_test, y_test = extract_full_data(test_generator)\n","x_test.shape, y_test.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-08T14:33:25.964114Z","iopub.status.idle":"2024-06-08T14:33:25.964474Z","shell.execute_reply":"2024-06-08T14:33:25.964316Z","shell.execute_reply.started":"2024-06-08T14:33:25.964296Z"},"id":"loy2C8odT2Bt","trusted":true},"outputs":[],"source":["vocabulary = tokenizer.get_vocabulary()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-06-08T14:33:25.965724Z","iopub.status.idle":"2024-06-08T14:33:25.966060Z","shell.execute_reply":"2024-06-08T14:33:25.965913Z","shell.execute_reply.started":"2024-06-08T14:33:25.965899Z"},"id":"HbQTmbHmX_u8","outputId":"dc98aea9-7f75-499f-e0c8-6ca5b883e5d0","trusted":true},"outputs":[],"source":["x_train, y_train = extract_full_data(train_generator)\n","x_train.shape, x_train.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-08T14:33:25.967602Z","iopub.status.idle":"2024-06-08T14:33:25.968075Z","shell.execute_reply":"2024-06-08T14:33:25.967858Z","shell.execute_reply.started":"2024-06-08T14:33:25.967838Z"},"id":"BDz_RRaCRRTJ","trusted":true},"outputs":[],"source":["from keras.utils import pad_sequences\n","def prepare_dataset(X, Y):\n","  c_set = pad_sequences(np.array([s[1:] for s in X]), maxlen=28, padding='post')\n","  x_set = Y\n","  y_set = pad_sequences(np.array([s[1:] for s in Y]), maxlen=28, padding='post')\n","  context = []\n","  labels = []\n","  inputs= []\n","\n","  for j,x in enumerate(x_set):\n","    non_null_count = sum(x>0)-2\n","    for i in range(non_null_count):\n","      context.append(c_set[j])\n","      inputs.append(pad_sequences([x[:i+1]], maxlen=28, padding='post')[0])\n","      labels.append(y_set[j])\n","\n","  return np.array(context), np.array(inputs), np.array(labels)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-08T14:33:25.969321Z","iopub.status.idle":"2024-06-08T14:33:25.969680Z","shell.execute_reply":"2024-06-08T14:33:25.969515Z","shell.execute_reply.started":"2024-06-08T14:33:25.969501Z"},"trusted":true},"outputs":[],"source":["x_train.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-08T14:33:25.971093Z","iopub.status.idle":"2024-06-08T14:33:25.971450Z","shell.execute_reply":"2024-06-08T14:33:25.971267Z","shell.execute_reply.started":"2024-06-08T14:33:25.971254Z"},"id":"DbICPbKkSn48","trusted":true},"outputs":[],"source":["context_train, inputs_train, labels_train = prepare_dataset(x_train[:200000], y_train[:200000])\n","context_val, inputs_val, labels_val = prepare_dataset(x_train[200000:], y_train[200000:])\n","context_test, inputs_test, labels_test = prepare_dataset(x_test, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-06-08T14:33:25.972846Z","iopub.status.idle":"2024-06-08T14:33:25.973194Z","shell.execute_reply":"2024-06-08T14:33:25.973038Z","shell.execute_reply.started":"2024-06-08T14:33:25.973023Z"},"id":"GcO4N4_ijvz6","outputId":"426da502-813b-42be-f65d-fe3bb6736e7b","trusted":true},"outputs":[],"source":["len(context_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-06-08T14:33:25.974645Z","iopub.status.idle":"2024-06-08T14:33:25.974971Z","shell.execute_reply":"2024-06-08T14:33:25.974833Z","shell.execute_reply.started":"2024-06-08T14:33:25.974820Z"},"id":"JDUXVP-ScbTj","outputId":"f4577a93-f662-4411-cbce-de292143cadc","trusted":true},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","import keras.backend as k\n","def positional_encoding(length, depth):\n","    depth = depth/2\n","\n","    positions = np.arange(length)[:, np.newaxis]     # (seq, 1)\n","    depths = np.arange(depth)[np.newaxis, :]/depth   # (1, depth)\n","\n","    angle_rates = 1 / (10000**depths)         # (1, depth)\n","    angle_rads = positions * angle_rates      # (pos, depth)\n","\n","    pos_encoding = np.concatenate(\n","        [np.sin(angle_rads), np.cos(angle_rads)],\n","        axis=-1)\n","\n","    return tf.cast(pos_encoding, dtype=tf.float32)\n","class BaseAttention(tf.keras.layers.Layer):\n","    def __init__(self, **kwargs):\n","        super().__init__()\n","        self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n","        self.layernorm = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","        self.add = tf.keras.layers.Add()\n","class CrossAttention(BaseAttention):\n","    def call(self, x, context):\n","        attn_output, att_scores = self.mha(\n","            query=x,\n","            key=context,\n","            value=context,\n","            return_attention_scores=True\n","        )\n","        self.last_attn_scores = att_scores\n","\n","        x = self.add([x, attn_output])\n","        x = self.layernorm(x)\n","        return x\n","\n","class PositionalEmbedding(tf.keras.layers.Layer):\n","    def __init__(self, embedder, vocab_size, d_model):\n","        super().__init__()\n","        self.d_model = d_model\n","        self.embedding = embedder\n","        self.pos_encoding = positional_encoding(length=2048, depth=d_model)\n","    def compute_mask(self, *args, **kwargs):\n","        return self.embedding.compute_mask(*args, **kwargs)\n","    def call(self, x):\n","        length = tf.shape(x)[1]\n","        x = self.embedding(x)\n","        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n","        x += self.pos_encoding[tf.newaxis, :length, :]\n","        return x\n","class GlobalSelfAttention(BaseAttention):\n","    def call(self, x):\n","        attn_output = self.mha(\n","            query=x,\n","            value=x,\n","            key=x\n","        )\n","        x = self.add([x, attn_output])\n","        x = self.layernorm(x)\n","        return x\n","class CausalSelfAttention(BaseAttention):\n","  def call(self, x):\n","    attn_output = self.mha(\n","        query=x,\n","        value=x,\n","        key=x,\n","        use_causal_mask = True)\n","    x = self.add([x, attn_output])\n","    x = self.layernorm(x)\n","    return x\n","\n","class FeedForward(tf.keras.layers.Layer):\n","  def __init__(self, d_model, dff, dropout_rate=0.1):\n","    super().__init__()\n","    self.seq = tf.keras.Sequential([\n","      tf.keras.layers.Dense(dff, activation='relu'),\n","      tf.keras.layers.Dense(d_model),\n","      tf.keras.layers.Dropout(dropout_rate)\n","    ])\n","    self.add = tf.keras.layers.Add()\n","    self.layer_norm = tf.keras.layers.LayerNormalization()\n","\n","  def call(self, x):\n","    x = self.add([x, self.seq(x)])\n","    x = self.layer_norm(x)\n","    return x\n","\n","class EncoderLayer(tf.keras.layers.Layer):\n","  def __init__(self,*, d_model, num_heads, dff, dropout_rate=0.1):\n","    super().__init__()\n","\n","    self.self_attention = GlobalSelfAttention(\n","        num_heads=num_heads,\n","        key_dim=d_model,\n","        dropout=dropout_rate)\n","\n","    self.ffn = FeedForward(d_model, dff)\n","\n","  def call(self, x):\n","    x = self.self_attention(x)\n","    x = self.ffn(x)\n","    return x\n","\n","class Encoder(tf.keras.layers.Layer):\n","  def __init__(self, embedder, num_layers, d_model, num_heads,\n","               dff, vocab_size, dropout_rate=0.1):\n","    super().__init__()\n","\n","    self.d_model = d_model\n","    self.num_layers = num_layers\n","\n","    self.embedding = embedder\n","\n","    self.enc_layers = [\n","        EncoderLayer(d_model=d_model,\n","                     num_heads=num_heads,\n","                     dff=dff,\n","                     dropout_rate=dropout_rate)\n","        for _ in range(num_layers)]\n","    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n","\n","  def call(self, x):\n","    # `x` is token-IDs shape: (batch, seq_len)\n","    x = self.embedding(x)  # Shape `(batch_size, seq_len, d_model)`.\n","\n","    # Add dropout.\n","    x = self.dropout(x)\n","\n","    for i in range(self.num_layers):\n","      x = self.enc_layers[i](x)\n","\n","    return x\n","\n","class DecoderLayer(tf.keras.layers.Layer):\n","  def __init__(self,\n","               *,\n","               d_model,\n","               num_heads,\n","               dff,\n","               dropout_rate=0.1):\n","    super(DecoderLayer, self).__init__()\n","\n","    self.causal_self_attention = CausalSelfAttention(\n","        num_heads=num_heads,\n","        key_dim=d_model,\n","        dropout=dropout_rate)\n","\n","    self.cross_attention = CrossAttention(\n","        num_heads=num_heads,\n","        key_dim=d_model,\n","        dropout=dropout_rate)\n","\n","    self.ffn = FeedForward(d_model, dff)\n","\n","  def call(self, x, context):\n","    x = self.causal_self_attention(x=x)\n","    x = self.cross_attention(x=x, context=context)\n","\n","    # The last attention scores are cached for later plotting\n","    self.last_attn_scores = self.cross_attention.last_attn_scores\n","\n","    x = self.ffn(x)  # Shape `(batch_size, seq_len, d_model)`.\n","    return x\n","\n","class Decoder(tf.keras.layers.Layer):\n","  def __init__(self, embedder, num_layers, d_model, num_heads, dff, vocab_size,\n","               dropout_rate=0.1):\n","    super(Decoder, self).__init__()\n","\n","    self.d_model = d_model\n","    self.num_layers = num_layers\n","\n","    self.pos_embedding = PositionalEmbedding(embedder, vocab_size=vocab_size, d_model=d_model)\n","\n","    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n","    self.dec_layers = [\n","        DecoderLayer(d_model=d_model, num_heads=num_heads,\n","                     dff=dff, dropout_rate=dropout_rate)\n","        for _ in range(num_layers)]\n","\n","    self.last_attn_scores = None\n","\n","  def call(self, x, context):\n","    # `x` is token-IDs shape (batch, target_seq_len)\n","    x = self.pos_embedding(x)  # (batch_size, target_seq_len, d_model)\n","\n","    x = self.dropout(x)\n","\n","    for i in range(self.num_layers):\n","      x  = self.dec_layers[i](x, context)\n","\n","    self.last_attn_scores = self.dec_layers[-1].last_attn_scores\n","\n","    # The shape of x is (batch_size, target_seq_len, d_model).\n","    return x\n","  \n","import keras\n","\n","@keras.saving.register_keras_serializable()\n","class Transformer(tf.keras.Model):\n","  def __init__(self, *, num_layers, d_model, num_heads, dff,\n","               input_vocab_size, target_vocab_size, dropout_rate=0.1):\n","    super().__init__()\n","    self.embedder = tf.keras.layers.Embedding(input_vocab_size, d_model, mask_zero=True)\n","    self.encoder = Encoder(self.embedder,num_layers=num_layers, d_model=d_model,\n","                           num_heads=num_heads, dff=dff,\n","                           vocab_size=input_vocab_size,\n","                           dropout_rate=dropout_rate)\n","\n","    self.decoder = Decoder(self.embedder,num_layers=num_layers, d_model=d_model,\n","                           num_heads=num_heads, dff=dff,\n","                           vocab_size=target_vocab_size,\n","                           dropout_rate=dropout_rate)\n","\n","    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n","\n","  def call(self, inputs):\n","    # All inputs must be passed in the first argument to use '.fit'\n","\n","    context, x  = inputs\n","    context = self.encoder(context)  # (batch_size, context_len, d_model)\n","\n","    x = self.decoder(x, context)  # (batch_size, target_len, d_model)\n","\n","    # Final linear layer output.\n","    logits = self.final_layer(x)  # (batch_size, target_len, target_vocab_size)\n","\n","    try:\n","      # Keras mask is dropped, so it doesn't scale with losses or metrics.\n","      del logits._keras_mask\n","    except AttributeError:\n","      pass\n","\n","    # Return the final output and the attention weights.\n","    return logits\n","\n","@keras.saving.register_keras_serializable()\n","class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n","  def __init__(self, d_model, warmup_steps=4000):\n","    super().__init__()\n","\n","    self.d_model = d_model\n","    self.d_model = tf.cast(self.d_model, tf.float32)\n","\n","    self.warmup_steps = warmup_steps\n","\n","  def __call__(self, step):\n","    step = tf.cast(step, dtype=tf.float32)\n","    arg1 = tf.math.rsqrt(step)\n","    arg2 = step * (self.warmup_steps ** -1.5)\n","\n","    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n","  def get_config(self):\n","        return {\n","            'd_model': self.d_model,\n","            'warmup_steps': self.warmup_steps\n","        }\n","\n","\n","\n","# num_layers = 8\n","num_layers = 8\n","# d_model = 128\n","d_model = 128\n","# dff = 512\n","dff = 128\n","# num_heads = 8\n","num_heads = 4\n","dropout_rate = 0.2\n","transformer = Transformer(\n","    num_layers=num_layers,\n","    d_model=d_model,\n","    num_heads=num_heads,\n","    dff=dff,\n","    input_vocab_size=10_000,\n","    target_vocab_size=10_000,\n","    dropout_rate=dropout_rate)\n","learning_rate = CustomSchedule(d_model)\n","\n","optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n","                                     epsilon=1e-9)\n","\n","K_VALUE = 0.97\n","\n","# Defining a custom loss function that works directly on tokens\n","def custom_masked_loss(label, pred):\n","\n","    mask = label != 0\n","    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n","        from_logits=True, reduction='none')\n","    loss = loss_object(label, pred)\n","\n","    final_array = tf.pow(K_VALUE,tf.cast(tf.range(1,28+1),tf.float32))\n","\n","    mask = tf.cast(mask, dtype=loss.dtype)\n","    mask*=final_array\n","\n","    loss *= mask\n","\n","    loss = tf.reduce_sum(loss)/tf.reduce_sum(mask)\n","    return loss\n","\n","# Defining a custom metric that works directly on tokens\n","def masked_accuracy(label, pred):\n","    pred = tf.argmax(pred, axis=2)\n","    label = tf.cast(label, pred.dtype)\n","    match = label == pred\n","\n","    mask = label != 0\n","\n","    match = match & mask\n","\n","    match = tf.cast(match, dtype=tf.float32)\n","    mask = tf.cast(mask, dtype=tf.float32)\n","    return tf.reduce_sum(match)/tf.reduce_sum(mask)\n","\n","transformer.compile(\n","    loss=custom_masked_loss,\n","    optimizer=optimizer,\n","    metrics=[masked_accuracy])\n","\n","transformer.build(input_shape = [(None, 28), (None, 28)])\n","\n","transformer.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-06-08T14:33:25.976835Z","iopub.status.idle":"2024-06-08T14:33:25.977149Z","shell.execute_reply":"2024-06-08T14:33:25.977001Z","shell.execute_reply.started":"2024-06-08T14:33:25.976989Z"},"id":"tpxwXkYcdBEB","outputId":"acdc26fa-456d-4e2c-fda1-bf9843e71c00","trusted":true},"outputs":[],"source":["transformer.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-06-08T14:33:25.978627Z","iopub.status.idle":"2024-06-08T14:33:25.978975Z","shell.execute_reply":"2024-06-08T14:33:25.978819Z","shell.execute_reply.started":"2024-06-08T14:33:25.978804Z"},"id":"aDUhVKZUeajO","outputId":"61ef608b-c521-4b97-e289-37199757cd00","trusted":true},"outputs":[],"source":["# print(custom_masked_loss(y_train[0],result))\n","transformer.fit(\n","    (context_train[:1], inputs_train[:1]),\n","    labels_train[:1],\n","    epochs=1,\n","    batch_size=1,\n","    # callbacks = [es],\n","    validation_data = ((context_val[:1], inputs_val[:1]), labels_val[:1]))\n","transformer.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-08T14:33:25.979923Z","iopub.status.idle":"2024-06-08T14:33:25.980231Z","shell.execute_reply":"2024-06-08T14:33:25.980085Z","shell.execute_reply.started":"2024-06-08T14:33:25.980072Z"},"trusted":true},"outputs":[],"source":["print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-08T14:33:25.981411Z","iopub.status.idle":"2024-06-08T14:33:25.981747Z","shell.execute_reply":"2024-06-08T14:33:25.981603Z","shell.execute_reply.started":"2024-06-08T14:33:25.981589Z"},"trusted":true},"outputs":[],"source":["context_train.shape, context_val.shape, context_test.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-06-08T14:33:25.982884Z","iopub.status.idle":"2024-06-08T14:33:25.983210Z","shell.execute_reply":"2024-06-08T14:33:25.983056Z","shell.execute_reply.started":"2024-06-08T14:33:25.983043Z"},"id":"rwj_eBJyd6AU","outputId":"69790b14-5d21-4d62-c2ce-5ce72ab624a7","trusted":true},"outputs":[],"source":["from keras.callbacks import EarlyStopping, ModelCheckpoint\n","\n","# Callbacks\n","es = EarlyStopping(monitor='val_masked_accuracy', mode='max', verbose=1, patience=2)\n","\n","epochs = 5\n","batch_size= 128\n","\n","checkpoint_filepath = '/content/drive/MyDrive/UNIBO_DEEP_LEARNING/latest.weights.h5'\n","checkpoint_filepath = './latest.weights.h5'\n","checkpoint_callback = ModelCheckpoint(\n","    filepath=checkpoint_filepath,\n","    save_weights_only=True, \n","    save_best_only=True,\n","    monitor='masked_accuracy',# Only save the weights\n","    save_freq=1000,          # Save every 1000 weight updates\n","    verbose=1                # Verbosity level (optional)\n",")\n","history = transformer.fit(\n","    (context_train, inputs_train),\n","    labels_train,\n","    epochs=epochs,\n","    batch_size=batch_size,\n","    callbacks=[checkpoint_callback, es],\n","    validation_data = ((context_val, inputs_val), labels_val)\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-08T14:33:25.984542Z","iopub.status.idle":"2024-06-08T14:33:25.984879Z","shell.execute_reply":"2024-06-08T14:33:25.984730Z","shell.execute_reply.started":"2024-06-08T14:33:25.984716Z"},"trusted":true},"outputs":[],"source":["transformer.save_weights(\"weights_final.weights.h5\", overwrite=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"execution":{"iopub.status.busy":"2024-06-08T14:33:25.986273Z","iopub.status.idle":"2024-06-08T14:33:25.986608Z","shell.execute_reply":"2024-06-08T14:33:25.986468Z","shell.execute_reply.started":"2024-06-08T14:33:25.986455Z"},"id":"cca2YJU3kYOg","outputId":"80be4e87-02b5-4ccb-9f8c-7b885404f659","trusted":true},"outputs":[],"source":["\n","num_layers = 3\n","# d_model = 128\n","d_model = 64\n","# dff = 512\n","dff = 64\n","# num_heads = 8\n","num_heads = 3\n","dropout_rate = 0.2\n","transformer_small = Transformer(\n","    num_layers=num_layers,\n","    d_model=d_model,\n","    num_heads=num_heads,\n","    dff=dff,\n","    input_vocab_size=10_000,\n","    target_vocab_size=10_000,\n","    dropout_rate=dropout_rate)\n","learning_rate = CustomSchedule(d_model)\n","\n","optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n","                                     epsilon=1e-9)\n","\n","transformer_small.compile(\n","    loss=custom_masked_loss,\n","    optimizer=optimizer,\n","    metrics=[masked_accuracy])\n","\n","transformer_small.build(input_shape = [(None, 28), (None, 28)])\n","\n","transformer_small.summary()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-08T14:33:25.987550Z","iopub.status.idle":"2024-06-08T14:33:25.987881Z","shell.execute_reply":"2024-06-08T14:33:25.987727Z","shell.execute_reply.started":"2024-06-08T14:33:25.987713Z"},"trusted":true},"outputs":[],"source":["transformer_small.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-08T14:33:25.989048Z","iopub.status.idle":"2024-06-08T14:33:25.989388Z","shell.execute_reply":"2024-06-08T14:33:25.989216Z","shell.execute_reply.started":"2024-06-08T14:33:25.989203Z"},"trusted":true},"outputs":[],"source":["from keras.callbacks import EarlyStopping, ModelCheckpoint\n","\n","# Callbacks\n","es = EarlyStopping(monitor='val_masked_accuracy', mode='max', verbose=1, patience=2)\n","\n","epochs = 2\n","batch_size= 128\n","\n","checkpoint_filepath = '/content/drive/MyDrive/UNIBO_DEEP_LEARNING/latest.weights.h5'\n","checkpoint_filepath = './latest_small.weights.h5'\n","checkpoint_callback = ModelCheckpoint(\n","    filepath=checkpoint_filepath,\n","    save_weights_only=True, \n","    save_best_only=True,\n","    monitor='masked_accuracy',# Only save the weights\n","    save_freq=1000,          # Save every 1000 weight updates\n","    verbose=1                # Verbosity level (optional)\n",")\n","history = transformer_small.fit(\n","    (context_train, inputs_train),\n","    labels_train,\n","    epochs=epochs,\n","    batch_size=batch_size,\n","    callbacks=[checkpoint_callback, es],\n","    validation_data = ((context_val, inputs_val), labels_val)\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-08T14:33:25.991145Z","iopub.status.idle":"2024-06-08T14:33:25.991520Z","shell.execute_reply":"2024-06-08T14:33:25.991349Z","shell.execute_reply.started":"2024-06-08T14:33:25.991334Z"},"trusted":true},"outputs":[],"source":["\n","num_layers = 8\n","# d_model = 128\n","d_model = 128\n","# dff = 512\n","dff = 128\n","# num_heads = 8\n","num_heads = 8\n","dropout_rate = 0.2\n","transformer_big = Transformer(\n","    num_layers=num_layers,\n","    d_model=d_model,\n","    num_heads=num_heads,\n","    dff=dff,\n","    input_vocab_size=10_000,\n","    target_vocab_size=10_000,\n","    dropout_rate=dropout_rate)\n","learning_rate = CustomSchedule(d_model)\n","\n","optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n","                                     epsilon=1e-9)\n","\n","transformer_big.compile(\n","    loss=custom_masked_loss,\n","    optimizer=optimizer,\n","    metrics=[masked_accuracy])\n","\n","transformer_big.build(input_shape = [(None, 28), (None, 28)])\n","\n","transformer_big.summary()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-08T14:33:25.992677Z","iopub.status.idle":"2024-06-08T14:33:25.992981Z","shell.execute_reply":"2024-06-08T14:33:25.992842Z","shell.execute_reply.started":"2024-06-08T14:33:25.992829Z"},"trusted":true},"outputs":[],"source":["transformer_big.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-08T14:33:25.994021Z","iopub.status.idle":"2024-06-08T14:33:25.994355Z","shell.execute_reply":"2024-06-08T14:33:25.994189Z","shell.execute_reply.started":"2024-06-08T14:33:25.994177Z"},"trusted":true},"outputs":[],"source":["from keras.callbacks import EarlyStopping, ModelCheckpoint\n","\n","# Callbacks\n","es = EarlyStopping(monitor='val_masked_accuracy', mode='max', verbose=1, patience=2)\n","\n","epochs = 1\n","batch_size= 128\n","\n","checkpoint_filepath = '/content/drive/MyDrive/UNIBO_DEEP_LEARNING/latest.weights.h5'\n","checkpoint_filepath = './latest_big.weights.h5'\n","checkpoint_callback = ModelCheckpoint(\n","    filepath=checkpoint_filepath,\n","    save_weights_only=True, \n","    save_best_only=True,\n","    monitor='masked_accuracy',# Only save the weights\n","    save_freq=1000,          # Save every 1000 weight updates\n","    verbose=1                # Verbosity level (optional)\n",")\n","history = transformer_big.fit(\n","    (context_train, inputs_train),\n","    labels_train,\n","    epochs=epochs,\n","    batch_size=batch_size,\n","    callbacks=[checkpoint_callback, es],\n","    validation_data = ((context_val, inputs_val), labels_val)\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-08T14:33:25.995433Z","iopub.status.idle":"2024-06-08T14:33:25.995838Z","shell.execute_reply":"2024-06-08T14:33:25.995645Z","shell.execute_reply.started":"2024-06-08T14:33:25.995628Z"},"trusted":true},"outputs":[],"source":["average_random_score, average_generated_score = get_average_score(x_test[2000:2100], y_test[2000:2100], transformer_big)\n","print(f'Average score on shuffled data: {average_random_score}')\n","print(f'Average score on generated data: {average_generated_score}')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-08T14:33:25.996910Z","iopub.status.idle":"2024-06-08T14:33:25.997370Z","shell.execute_reply":"2024-06-08T14:33:25.997152Z","shell.execute_reply.started":"2024-06-08T14:33:25.997134Z"},"trusted":true},"outputs":[],"source":["average_random_score, average_generated_score = get_average_score(x_test[2000:2100], y_test[2000:2100], transformer_small)\n","print(f'Average score on shuffled data: {average_random_score}')\n","print(f'Average score on generated data: {average_generated_score}')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-08T14:33:26.004985Z","iopub.status.idle":"2024-06-08T14:33:26.005343Z","shell.execute_reply":"2024-06-08T14:33:26.005162Z","shell.execute_reply.started":"2024-06-08T14:33:26.005148Z"},"trusted":true},"outputs":[],"source":["average_random_score, average_generated_score = get_average_score(x_train[2000:2100], y_train[2000:2100], transformer_small)\n","print(f'Average score on shuffled data: {average_random_score}')\n","print(f'Average score on generated data: {average_generated_score}')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-08T14:33:26.006541Z","iopub.status.idle":"2024-06-08T14:33:26.006878Z","shell.execute_reply":"2024-06-08T14:33:26.006730Z","shell.execute_reply.started":"2024-06-08T14:33:26.006716Z"},"trusted":true},"outputs":[],"source":["transformer2.get_weights()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-08T14:33:26.010299Z","iopub.status.idle":"2024-06-08T14:33:26.010682Z","shell.execute_reply":"2024-06-08T14:33:26.010517Z","shell.execute_reply.started":"2024-06-08T14:33:26.010502Z"},"trusted":true},"outputs":[],"source":["\n","np.argmax(transformer.predict((np.array([context_train[0]]), np.array([inputs_train[0]]))),axis=-1) == np.argmax(transformer2.predict((np.array([context_train[0]]), np.array([inputs_train[0]]))),axis=-1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-08T14:33:26.011947Z","iopub.status.idle":"2024-06-08T14:33:26.012348Z","shell.execute_reply":"2024-06-08T14:33:26.012135Z","shell.execute_reply.started":"2024-06-08T14:33:26.012120Z"},"id":"tlG8YG_2jvz_","outputId":"f59d4c29-1cd3-441b-fd20-b018a3b2775b","trusted":true},"outputs":[],"source":["\n","result = transformer.predict((np.array([context_train[0]]), np.array([inputs_train[0]])))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-08T14:33:26.013389Z","iopub.status.idle":"2024-06-08T14:33:26.013731Z","shell.execute_reply":"2024-06-08T14:33:26.013565Z","shell.execute_reply.started":"2024-06-08T14:33:26.013551Z"},"id":"gkoVsS8xjv0A","outputId":"cc1b0c15-c53e-4933-dc5d-d26dfbef3ee3","trusted":true},"outputs":[],"source":["np.argmax(result,axis=2), labels_train[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-08T14:33:26.015788Z","iopub.status.idle":"2024-06-08T14:33:26.016128Z","shell.execute_reply":"2024-06-08T14:33:26.015974Z","shell.execute_reply.started":"2024-06-08T14:33:26.015960Z"},"trusted":true},"outputs":[],"source":["score(x[i],y[i])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-06-08T14:33:26.017172Z","iopub.status.idle":"2024-06-08T14:33:26.017526Z","shell.execute_reply":"2024-06-08T14:33:26.017374Z","shell.execute_reply.started":"2024-06-08T14:33:26.017359Z"},"id":"MTBc-9KSmQi8","outputId":"0b6455f5-6a8c-4ee9-dbb4-30560e7174f5","trusted":true},"outputs":[],"source":["# result = transformer.predict((np.array([context_train[1]]), np.array([inputs_train[1]])))\n","# score(labels_train[1],tf.argmax(result, axis=2)[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-08T14:33:26.018875Z","iopub.status.idle":"2024-06-08T14:33:26.019210Z","shell.execute_reply":"2024-06-08T14:33:26.019054Z","shell.execute_reply.started":"2024-06-08T14:33:26.019040Z"},"id":"JsxpW2uqjv0U","outputId":"09698630-cd88-4e02-b9bd-6329b23966c9","trusted":true},"outputs":[],"source":["# context_train[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-08T14:33:26.020731Z","iopub.status.idle":"2024-06-08T14:33:26.021177Z","shell.execute_reply":"2024-06-08T14:33:26.020960Z","shell.execute_reply.started":"2024-06-08T14:33:26.020943Z"},"id":"zzouxYn2jv0U","outputId":"c7f23ae2-dc67-4301-e641-61eccc1156ca","trusted":true},"outputs":[],"source":["# labels_train[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-06-08T14:33:26.022140Z","iopub.status.idle":"2024-06-08T14:33:26.022555Z","shell.execute_reply":"2024-06-08T14:33:26.022367Z","shell.execute_reply.started":"2024-06-08T14:33:26.022350Z"},"id":"hhkpX8oGEK3a","outputId":"40915699-bd25-44c6-c13d-389daa421a88","trusted":true},"outputs":[],"source":["available_tokens = context_train[0][1:sum((context_train[0]>0))-1].tolist()\n","print(available_tokens)\n","relevant_logits = result[0, 0, available_tokens]\n","print(relevant_logits)\n","available_tokens[np.argmax(relevant_logits,axis=-1)]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-08T14:33:26.023913Z","iopub.status.idle":"2024-06-08T14:33:26.024343Z","shell.execute_reply":"2024-06-08T14:33:26.024134Z","shell.execute_reply.started":"2024-06-08T14:33:26.024109Z"},"id":"nuvJ5RkhYciw","trusted":true},"outputs":[],"source":["vocabulary_size = len(vocabulary)\n","batch_size = 32"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-08T14:33:26.026330Z","iopub.status.idle":"2024-06-08T14:33:26.026960Z","shell.execute_reply":"2024-06-08T14:33:26.026784Z","shell.execute_reply.started":"2024-06-08T14:33:26.026760Z"},"id":"VWKTreHjZr6z","trusted":true},"outputs":[],"source":["test_generator = ModifiedDataGenerator((x_test,y_test), batch_size=batch_size, vocabulary_size=vocabulary_size)\n","train_generator = ModifiedDataGenerator((x_train,y_train), batch_size=batch_size, vocabulary_size=vocabulary_size)\n"]},{"cell_type":"code","execution_count":163,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-06-08T17:18:43.859182Z","iopub.status.busy":"2024-06-08T17:18:43.858796Z","iopub.status.idle":"2024-06-08T17:18:43.873746Z","shell.execute_reply":"2024-06-08T17:18:43.872680Z","shell.execute_reply.started":"2024-06-08T17:18:43.859150Z"},"id":"pLTKIOoSbu9l","outputId":"4d344b89-b34f-41b1-b668-e747905c0693","trusted":true},"outputs":[],"source":["from difflib import SequenceMatcher\n","from keras.preprocessing.sequence import pad_sequences\n","\n","def score(s, p):\n","    match = SequenceMatcher(None, s, p).find_longest_match(0, len(s), 0, len(p))\n","    return match.size / max(len(p), len(s))\n","\n","# Limit the number of examples for testing\n","\n","def generate_prediction(shuffled, model):\n","    max_count = sum(shuffled > 3)\n","    generated = pad_sequences(np.array([shuffled[:1]]), maxlen=28, padding='post')[0]\n","    available_tokens = shuffled[1:sum((shuffled>0))-1].tolist()\n","    context = pad_sequences(np.array([shuffled[1:]]), maxlen=28, padding='post')[0]\n","    for count in range(max_count):\n","        prediction = model.predict((np.array([context]), np.array([generated])), verbose=0) \n","        relevant_logits = prediction[0, count, available_tokens]\n","        generated_index = np.argmax(relevant_logits, axis=-1)\n","        generated_token = available_tokens[generated_index]\n","        available_tokens.remove(generated_token)\n","        generated[count+1] = generated_token\n","    \n","    return generated[1:sum(generated>0)]\n","\n","# def generate_prediction2(shuffled, model):\n","#     max_count = sum(shuffled > 3)\n","#     generated = pad_sequences(np.array([shuffled[:1]]), maxlen=28, padding='post')[0]\n","# #     available_tokens = shuffled[1:sum((shuffled>0))-1].tolist()\n","#     context = pad_sequences(np.array([shuffled[1:]]), maxlen=28, padding='post')[0]\n","#     for count in range(max_count):\n","#         prediction = model.predict((np.array([context]), np.array([generated])), verbose=0) \n","#         relevant_logits = prediction[0, count, :]\n","#         generated_index = np.argmax(relevant_logits, axis=-1)\n","#         generated_token = generated_index\n","# #         generated_token = available_tokens[generated_index]\n","# #         available_tokens.remove(generated_token)\n","#         generated[count+1] = generated_token\n","    \n","#     generated[sum(generated>0)] = 2\n","#     return generated[:sum(generated>0)]\n","# def get_average_score2(x, y, model):\n","#     num_examples = len(x)\n","#     rs = []\n","#     gs = []\n","#     for i in range(num_examples):\n","#         shuffled = x[i][:sum(x[i]>0)]\n","#         ordered = y[i][:sum(y[i]>0)]\n","\n","#         rs.append(score(ordered, shuffled))\n","#         gs.append(score(ordered, generate_prediction2(x[i],model)))\n","#         print(f'{i+1}.Random: {rs[-1]}')\n","#         print(f'{i+1}.Generated: {gs[-1]}')\n","\n","#     return sum(rs)/num_examples, sum(gs)/num_examples\n","def get_average_score(x, y, model, print_allowed=False):\n","    num_examples = len(x)\n","    rs = []\n","    gs = []\n","    for i in range(num_examples):\n","        shuffled = x[i][1:sum(x[i]>0)-1]\n","        ordered = y[i][1:sum(y[i]>0)-1]\n","\n","        rs.append(score(ordered, shuffled))\n","        gs.append(score(ordered, generate_prediction(x[i],model)))\n","        if print_allowed:\n","            print(f'{i+1}.Random: {rs[-1]}')\n","            print(f'{i+1}.Generated: {gs[-1]}')\n","\n","    return gs, sum(rs)/num_examples, sum(gs)/num_examples"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-08T14:33:26.029912Z","iopub.status.idle":"2024-06-08T14:33:26.030293Z","shell.execute_reply":"2024-06-08T14:33:26.030109Z","shell.execute_reply.started":"2024-06-08T14:33:26.030093Z"},"trusted":true},"outputs":[],"source":["average_random_score, average_generated_score = get_average_score(x_train[2000:2100], y_train[2000:2100], transformer)\n","print(f'Average score on shuffled data: {average_random_score}')\n","print(f'Average score on generated data: {average_generated_score}')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-08T14:33:26.032138Z","iopub.status.idle":"2024-06-08T14:33:26.032501Z","shell.execute_reply":"2024-06-08T14:33:26.032342Z","shell.execute_reply.started":"2024-06-08T14:33:26.032327Z"},"id":"m1gNHO6mjv0V","outputId":"92688fac-3909-4f74-ccc2-06a686f5999f","trusted":true},"outputs":[],"source":["average_random_score, average_generated_score = get_average_score(x_test[2000:2100], y_test[2000:2100], transformer)\n","print(f'Average score on shuffled data: {average_random_score}')\n","print(f'Average score on generated data: {average_generated_score}')"]},{"cell_type":"markdown","metadata":{"id":"Fo8MazCGBTv3"},"source":["# Metrics"]},{"cell_type":"markdown","metadata":{"id":"G0NOkuO0CfPo"},"source":["Let s be the source string and p your prediction. The quality of the results will be measured according to the following metric:\n","\n","1.  look for the longest substring w between s and p\n","2.  compute |w|/max(|s|,|p|)\n","\n","If the match is exact, the score is 1.\n","\n","When computing the score, you should NOT consider the start and end tokens.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"a-aUrdlXDdVf"},"source":["The longest common substring can be computed with the SequenceMatcher function of difflib, that allows a simple definition of our metric."]},{"cell_type":"markdown","metadata":{"id":"RB2YfjXNExM-"},"source":["Let's do an example."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-06-08T14:33:26.033697Z","iopub.status.idle":"2024-06-08T14:33:26.034027Z","shell.execute_reply":"2024-06-08T14:33:26.033880Z","shell.execute_reply.started":"2024-06-08T14:33:26.033866Z"},"id":"h17C8bVjEwur","outputId":"37daae9d-2f0b-4c35-984a-7dea8f4df600","trusted":true},"outputs":[],"source":["original = \"at first henry wanted to be friends with the king of france\"\n","generated = \"henry wanted to be friends with king of france at the first\"\n","\n","print(\"your score is \",score(original,generated))"]},{"cell_type":"markdown","metadata":{"id":"BET8GqBvFugR"},"source":["The score must be computed as an average of at least 3K random examples taken form the test set."]},{"cell_type":"markdown","metadata":{"id":"4fwo7xj4GBW1"},"source":["# What to deliver"]},{"cell_type":"markdown","metadata":{"id":"i6uITuxOGHfJ"},"source":["You are supposed to deliver a single notebook, suitably commented.\n","The notebook should describe a single model, although you may briefly discuss additional attempts you did.\n","\n","The notebook should contain a full trace of the training.\n","Weights should be made available on request.\n","\n","You must also give a clear assesment of the performance of the model, computed with the metric that has been given to you.\n","\n","# Good work!"]},{"cell_type":"code","execution_count":161,"metadata":{"execution":{"iopub.execute_input":"2024-06-08T15:27:18.990122Z","iopub.status.busy":"2024-06-08T15:27:18.989550Z","iopub.status.idle":"2024-06-08T15:27:19.111745Z","shell.execute_reply":"2024-06-08T15:27:19.110832Z","shell.execute_reply.started":"2024-06-08T15:27:18.990090Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:361: UserWarning: `build()` was called on layer 'transformer_21', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n","  warnings.warn(\n"]},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer_21\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mModel: \"transformer_21\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n","<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n","\n"," positional_embedding_34          ?                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbedding</span>)                                                  \n","\n"," positional_embedding_35          ?                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbedding</span>)                                                  \n","\n"," transformer_encoder_177          ?                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)                                                   \n","\n"," transformer_encoder_178          ?                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)                                                   \n","\n"," transformer_encoder_179          ?                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)                                                   \n","\n"," transformer_encoder_180          ?                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)                                                   \n","\n"," transformer_encoder_181          ?                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)                                                   \n","\n"," transformer_encoder_182          ?                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)                                                   \n","\n"," transformer_encoder_183          ?                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)                                                   \n","\n"," transformer_encoder_184          ?                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)                                                   \n","\n"," transformer_encoder_185          ?                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)                                                   \n","\n"," transformer_encoder_186          ?                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)                                                   \n","\n"," transformer_encoder_187          ?                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)                                                   \n","\n"," transformer_encoder_188          ?                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)                                                   \n","\n"," transformer_encoder_189          ?                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)                                                   \n","\n"," transformer_encoder_190          ?                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)                                                   \n","\n"," transformer_encoder_191          ?                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)                                                   \n","\n"," transformer_encoder_192          ?                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)                                                   \n","\n"," transformer_decoder_135          ?                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoder</span>)                                                   \n","\n"," transformer_decoder_136          ?                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoder</span>)                                                   \n","\n"," transformer_decoder_137          ?                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoder</span>)                                                   \n","\n"," transformer_decoder_138          ?                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoder</span>)                                                   \n","\n"," transformer_decoder_139          ?                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoder</span>)                                                   \n","\n"," transformer_decoder_140          ?                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoder</span>)                                                   \n","\n"," transformer_decoder_141          ?                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoder</span>)                                                   \n","\n"," transformer_decoder_142          ?                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoder</span>)                                                   \n","\n"," transformer_decoder_143          ?                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoder</span>)                                                   \n","\n"," transformer_decoder_144          ?                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoder</span>)                                                   \n","\n"," transformer_decoder_145          ?                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoder</span>)                                                   \n","\n"," transformer_decoder_146          ?                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoder</span>)                                                   \n","\n"," transformer_decoder_147          ?                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoder</span>)                                                   \n","\n"," transformer_decoder_148          ?                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoder</span>)                                                   \n","\n"," transformer_decoder_149          ?                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoder</span>)                                                   \n","\n"," transformer_decoder_150          ?                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoder</span>)                                                   \n","\n"," dense_221 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                ?                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \n","\n","</pre>\n"],"text/plain":["\n","\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n","\n"," positional_embedding_34          ?                         \u001b[38;5;34m0\u001b[0m (unbuilt) \n"," (\u001b[38;5;33mPositionalEmbedding\u001b[0m)                                                  \n","\n"," positional_embedding_35          ?                         \u001b[38;5;34m0\u001b[0m (unbuilt) \n"," (\u001b[38;5;33mPositionalEmbedding\u001b[0m)                                                  \n","\n"," transformer_encoder_177          ?                         \u001b[38;5;34m0\u001b[0m (unbuilt) \n"," (\u001b[38;5;33mTransformerEncoder\u001b[0m)                                                   \n","\n"," transformer_encoder_178          ?                         \u001b[38;5;34m0\u001b[0m (unbuilt) \n"," (\u001b[38;5;33mTransformerEncoder\u001b[0m)                                                   \n","\n"," transformer_encoder_179          ?                         \u001b[38;5;34m0\u001b[0m (unbuilt) \n"," (\u001b[38;5;33mTransformerEncoder\u001b[0m)                                                   \n","\n"," transformer_encoder_180          ?                         \u001b[38;5;34m0\u001b[0m (unbuilt) \n"," (\u001b[38;5;33mTransformerEncoder\u001b[0m)                                                   \n","\n"," transformer_encoder_181          ?                         \u001b[38;5;34m0\u001b[0m (unbuilt) \n"," (\u001b[38;5;33mTransformerEncoder\u001b[0m)                                                   \n","\n"," transformer_encoder_182          ?                         \u001b[38;5;34m0\u001b[0m (unbuilt) \n"," (\u001b[38;5;33mTransformerEncoder\u001b[0m)                                                   \n","\n"," transformer_encoder_183          ?                         \u001b[38;5;34m0\u001b[0m (unbuilt) \n"," (\u001b[38;5;33mTransformerEncoder\u001b[0m)                                                   \n","\n"," transformer_encoder_184          ?                         \u001b[38;5;34m0\u001b[0m (unbuilt) \n"," (\u001b[38;5;33mTransformerEncoder\u001b[0m)                                                   \n","\n"," transformer_encoder_185          ?                         \u001b[38;5;34m0\u001b[0m (unbuilt) \n"," (\u001b[38;5;33mTransformerEncoder\u001b[0m)                                                   \n","\n"," transformer_encoder_186          ?                         \u001b[38;5;34m0\u001b[0m (unbuilt) \n"," (\u001b[38;5;33mTransformerEncoder\u001b[0m)                                                   \n","\n"," transformer_encoder_187          ?                         \u001b[38;5;34m0\u001b[0m (unbuilt) \n"," (\u001b[38;5;33mTransformerEncoder\u001b[0m)                                                   \n","\n"," transformer_encoder_188          ?                         \u001b[38;5;34m0\u001b[0m (unbuilt) \n"," (\u001b[38;5;33mTransformerEncoder\u001b[0m)                                                   \n","\n"," transformer_encoder_189          ?                         \u001b[38;5;34m0\u001b[0m (unbuilt) \n"," (\u001b[38;5;33mTransformerEncoder\u001b[0m)                                                   \n","\n"," transformer_encoder_190          ?                         \u001b[38;5;34m0\u001b[0m (unbuilt) \n"," (\u001b[38;5;33mTransformerEncoder\u001b[0m)                                                   \n","\n"," transformer_encoder_191          ?                         \u001b[38;5;34m0\u001b[0m (unbuilt) \n"," (\u001b[38;5;33mTransformerEncoder\u001b[0m)                                                   \n","\n"," transformer_encoder_192          ?                         \u001b[38;5;34m0\u001b[0m (unbuilt) \n"," (\u001b[38;5;33mTransformerEncoder\u001b[0m)                                                   \n","\n"," transformer_decoder_135          ?                         \u001b[38;5;34m0\u001b[0m (unbuilt) \n"," (\u001b[38;5;33mTransformerDecoder\u001b[0m)                                                   \n","\n"," transformer_decoder_136          ?                         \u001b[38;5;34m0\u001b[0m (unbuilt) \n"," (\u001b[38;5;33mTransformerDecoder\u001b[0m)                                                   \n","\n"," transformer_decoder_137          ?                         \u001b[38;5;34m0\u001b[0m (unbuilt) \n"," (\u001b[38;5;33mTransformerDecoder\u001b[0m)                                                   \n","\n"," transformer_decoder_138          ?                         \u001b[38;5;34m0\u001b[0m (unbuilt) \n"," (\u001b[38;5;33mTransformerDecoder\u001b[0m)                                                   \n","\n"," transformer_decoder_139          ?                         \u001b[38;5;34m0\u001b[0m (unbuilt) \n"," (\u001b[38;5;33mTransformerDecoder\u001b[0m)                                                   \n","\n"," transformer_decoder_140          ?                         \u001b[38;5;34m0\u001b[0m (unbuilt) \n"," (\u001b[38;5;33mTransformerDecoder\u001b[0m)                                                   \n","\n"," transformer_decoder_141          ?                         \u001b[38;5;34m0\u001b[0m (unbuilt) \n"," (\u001b[38;5;33mTransformerDecoder\u001b[0m)                                                   \n","\n"," transformer_decoder_142          ?                         \u001b[38;5;34m0\u001b[0m (unbuilt) \n"," (\u001b[38;5;33mTransformerDecoder\u001b[0m)                                                   \n","\n"," transformer_decoder_143          ?                         \u001b[38;5;34m0\u001b[0m (unbuilt) \n"," (\u001b[38;5;33mTransformerDecoder\u001b[0m)                                                   \n","\n"," transformer_decoder_144          ?                         \u001b[38;5;34m0\u001b[0m (unbuilt) \n"," (\u001b[38;5;33mTransformerDecoder\u001b[0m)                                                   \n","\n"," transformer_decoder_145          ?                         \u001b[38;5;34m0\u001b[0m (unbuilt) \n"," (\u001b[38;5;33mTransformerDecoder\u001b[0m)                                                   \n","\n"," transformer_decoder_146          ?                         \u001b[38;5;34m0\u001b[0m (unbuilt) \n"," (\u001b[38;5;33mTransformerDecoder\u001b[0m)                                                   \n","\n"," transformer_decoder_147          ?                         \u001b[38;5;34m0\u001b[0m (unbuilt) \n"," (\u001b[38;5;33mTransformerDecoder\u001b[0m)                                                   \n","\n"," transformer_decoder_148          ?                         \u001b[38;5;34m0\u001b[0m (unbuilt) \n"," (\u001b[38;5;33mTransformerDecoder\u001b[0m)                                                   \n","\n"," transformer_decoder_149          ?                         \u001b[38;5;34m0\u001b[0m (unbuilt) \n"," (\u001b[38;5;33mTransformerDecoder\u001b[0m)                                                   \n","\n"," transformer_decoder_150          ?                         \u001b[38;5;34m0\u001b[0m (unbuilt) \n"," (\u001b[38;5;33mTransformerDecoder\u001b[0m)                                                   \n","\n"," dense_221 (\u001b[38;5;33mDense\u001b[0m)                ?                         \u001b[38;5;34m0\u001b[0m (unbuilt) \n","\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"]},"metadata":{},"output_type":"display_data"}],"source":["import tensorflow as tf\n","import keras_nlp\n","import numpy as np\n","\n","# Positional Encoding Function\n","def positional_encoding(length, depth):\n","    depth = depth // 2\n","    positions = np.arange(length)[:, np.newaxis]  # (seq, 1)\n","    depths = np.arange(depth)[np.newaxis, :] / depth  # (1, depth)\n","    angle_rates = 1 / (10000 ** depths)  # (1, depth)\n","    angle_rads = positions * angle_rates  # (pos, depth)\n","    pos_encoding = np.concatenate([np.sin(angle_rads), np.cos(angle_rads)], axis=-1)\n","    return tf.cast(pos_encoding, dtype=tf.float32)\n","\n","# Custom Positional Embedding Class\n","class PositionalEmbedding(tf.keras.layers.Layer):\n","    def __init__(self, vocab_size, d_model):\n","        super(PositionalEmbedding, self).__init__()\n","        self.d_model = d_model\n","        self.embedding = tf.keras.layers.Embedding(vocab_size, d_model, mask_zero=True)\n","        self.pos_encoding = positional_encoding(length=2048, depth=d_model)\n","\n","    def compute_mask(self, *args, **kwargs):\n","        return self.embedding.compute_mask(*args, **kwargs)\n","\n","    def call(self, x):\n","        length = tf.shape(x)[1]\n","        x = self.embedding(x)\n","        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n","        x += self.pos_encoding[tf.newaxis, :length, :]\n","        return x\n","\n","import keras\n","\n","@keras.saving.register_keras_serializable()\n","class Transformer(tf.keras.Model):\n","    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, target_vocab_size, dropout_rate=0.1):\n","        super(Transformer, self).__init__()\n","        self.encoder_embedding = PositionalEmbedding(input_vocab_size, d_model)\n","        self.decoder_embedding = PositionalEmbedding(target_vocab_size, d_model)\n","        self.encoder_layers = [keras_nlp.layers.TransformerEncoder(\n","            intermediate_dim=dff,\n","            num_heads=num_heads,\n","            dropout=dropout_rate, activation='swish'\n","        ) for _ in range(num_layers)]\n","        self.decoder_layers = [keras_nlp.layers.TransformerDecoder(\n","            intermediate_dim=dff,\n","            num_heads=num_heads,\n","            dropout=dropout_rate, activation='swish'\n","        ) for _ in range(num_layers)]\n","        self.final_layer = tf.keras.layers.Dense(target_vocab_size, activation='swish')\n","\n","    def call(self, inputs):\n","        context, x = inputs\n","        context_mask = self.encoder_embedding.compute_mask(context)\n","        x_mask = self.decoder_embedding.compute_mask(x)\n","        \n","        context = self.encoder_embedding(context)\n","        for layer in self.encoder_layers:\n","            context = layer(context, padding_mask=context_mask)\n","        \n","        x = self.decoder_embedding(x)\n","        for layer in self.decoder_layers:\n","            x = layer(x, context, decoder_padding_mask=x_mask, encoder_padding_mask=context_mask)\n","        \n","        logits = self.final_layer(x)\n","        try:\n","            del logits._keras_mask\n","        except AttributeError:\n","            pass\n","        return logits\n","\n","@keras.saving.register_keras_serializable()\n","class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n","    def __init__(self, d_model, warmup_steps=4000):\n","        super(CustomSchedule, self).__init__()\n","        self.d_model = d_model\n","        self.d_model = tf.cast(self.d_model, tf.float32)\n","        self.warmup_steps = warmup_steps\n","\n","    def __call__(self, step):\n","        step = tf.cast(step, dtype=tf.float32)\n","        arg1 = tf.math.rsqrt(step)\n","        arg2 = step * (self.warmup_steps ** -1.5)\n","        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n","\n","    def get_config(self):\n","        return {'d_model': self.d_model, 'warmup_steps': self.warmup_steps}\n","\n","# Model Hyperparameters\n","num_layers = 16\n","d_model = 128\n","dff = 512\n","num_heads = 8\n","dropout_rate = 0.2\n","input_vocab_size = 10000\n","target_vocab_size = 10000\n","\n","# Instantiate the Transformer Model\n","transformer = Transformer(\n","    num_layers=num_layers,\n","    d_model=d_model,\n","    num_heads=num_heads,\n","    dff=dff,\n","    input_vocab_size=input_vocab_size,\n","    target_vocab_size=target_vocab_size,\n","    dropout_rate=dropout_rate\n",")\n","\n","# Learning Rate and Optimizer\n","learning_rate = CustomSchedule(d_model)\n","optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n","\n","# Custom Loss Function\n","K_VALUE = 0.97\n","\n","def custom_masked_loss(label, pred):\n","    mask = label != 0\n","    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n","    loss = loss_object(label, pred)\n","#     1\n","#     final_array = tf.pow(K_VALUE, tf.cast(tf.range(1, 28 + 1), tf.float32))\n","    first_part = tf.pow(K_VALUE, tf.cast(tf.range(1, 6 + 1), tf.float32))\n","    second_part = tf.pow(K_VALUE, tf.cast(tf.range(1, 22 + 1), tf.float32))\n","\n","# Reverse the first part\n","    reversed_first_part = tf.reverse(first_part, axis=[0])\n","\n","# Concatenate the reversed first part with the second part\n","    final_array = tf.concat([reversed_first_part, second_part], axis=0)\n","    \n","    mask = tf.cast(mask, dtype=loss.dtype)\n","    mask *= final_array\n","    loss *= mask\n","    loss = tf.reduce_sum(loss) / tf.reduce_sum(mask)\n","    return loss\n","\n","def masked_accuracy(label, pred):\n","    pred = tf.argmax(pred, axis=2)\n","    label = tf.cast(label, pred.dtype)\n","    match = label == pred\n","\n","    mask = label != 0\n","\n","    match = match & mask\n","\n","    match = tf.cast(match, dtype=tf.float32)\n","    mask = tf.cast(mask, dtype=tf.float32)\n","    return tf.reduce_sum(match)/tf.reduce_sum(mask)\n","\n","# Compile the Model\n","transformer.compile(\n","    loss=custom_masked_loss,\n","    optimizer=optimizer,\n","    metrics=[masked_accuracy]\n",")\n","\n","# Build and Display the Model Summary\n","transformer.build(input_shape=[(None, 28), (None, 28)])\n","transformer.summary()\n"]},{"cell_type":"code","execution_count":162,"metadata":{"execution":{"iopub.execute_input":"2024-06-08T15:27:38.081151Z","iopub.status.busy":"2024-06-08T15:27:38.080527Z","iopub.status.idle":"2024-06-08T17:18:21.991654Z","shell.execute_reply":"2024-06-08T17:18:21.990101Z","shell.execute_reply.started":"2024-06-08T15:27:38.081116Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1717860699.552913     118 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m  999/19272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m47:09\u001b[0m 155ms/step - loss: 8.0514 - masked_accuracy: 0.1459\n","Epoch 1: masked_accuracy improved from -inf to 0.21420, saving model to ./latest_2.weights.h5\n","\u001b[1m 1999/19272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m44:47\u001b[0m 156ms/step - loss: 7.0642 - masked_accuracy: 0.2027\n","Epoch 1: masked_accuracy improved from 0.21420 to 0.30043, saving model to ./latest_2.weights.h5\n","\u001b[1m 2999/19272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m42:17\u001b[0m 156ms/step - loss: 6.3681 - masked_accuracy: 0.2453\n","Epoch 1: masked_accuracy improved from 0.30043 to 0.35614, saving model to ./latest_2.weights.h5\n","\u001b[1m 3999/19272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m39:41\u001b[0m 156ms/step - loss: 5.8460 - masked_accuracy: 0.2777\n","Epoch 1: masked_accuracy improved from 0.35614 to 0.39100, saving model to ./latest_2.weights.h5\n","\u001b[1m 4999/19272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m37:07\u001b[0m 156ms/step - loss: 5.4396 - masked_accuracy: 0.3031\n","Epoch 1: masked_accuracy improved from 0.39100 to 0.41757, saving model to ./latest_2.weights.h5\n","\u001b[1m 5999/19272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m34:31\u001b[0m 156ms/step - loss: 5.1109 - masked_accuracy: 0.3241\n","Epoch 1: masked_accuracy improved from 0.41757 to 0.43997, saving model to ./latest_2.weights.h5\n","\u001b[1m 6999/19272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m31:56\u001b[0m 156ms/step - loss: 4.8375 - masked_accuracy: 0.3421\n","Epoch 1: masked_accuracy improved from 0.43997 to 0.45956, saving model to ./latest_2.weights.h5\n","\u001b[1m 7999/19272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m29:20\u001b[0m 156ms/step - loss: 4.6053 - masked_accuracy: 0.3579\n","Epoch 1: masked_accuracy improved from 0.45956 to 0.47660, saving model to ./latest_2.weights.h5\n","\u001b[1m 8999/19272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m26:45\u001b[0m 156ms/step - loss: 4.4049 - masked_accuracy: 0.3719\n","Epoch 1: masked_accuracy improved from 0.47660 to 0.49167, saving model to ./latest_2.weights.h5\n","\u001b[1m 9999/19272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m24:09\u001b[0m 156ms/step - loss: 4.2297 - masked_accuracy: 0.3846\n","Epoch 1: masked_accuracy improved from 0.49167 to 0.50519, saving model to ./latest_2.weights.h5\n","\u001b[1m10999/19272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21:33\u001b[0m 156ms/step - loss: 4.0748 - masked_accuracy: 0.3961\n","Epoch 1: masked_accuracy improved from 0.50519 to 0.51737, saving model to ./latest_2.weights.h5\n","\u001b[1m11999/19272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18:57\u001b[0m 156ms/step - loss: 3.9365 - masked_accuracy: 0.4067\n","Epoch 1: masked_accuracy improved from 0.51737 to 0.52850, saving model to ./latest_2.weights.h5\n","\u001b[1m12999/19272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m16:21\u001b[0m 156ms/step - loss: 3.8121 - masked_accuracy: 0.4164\n","Epoch 1: masked_accuracy improved from 0.52850 to 0.53878, saving model to ./latest_2.weights.h5\n","\u001b[1m13999/19272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13:44\u001b[0m 156ms/step - loss: 3.6994 - masked_accuracy: 0.4255\n","Epoch 1: masked_accuracy improved from 0.53878 to 0.54837, saving model to ./latest_2.weights.h5\n","\u001b[1m14999/19272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11:08\u001b[0m 157ms/step - loss: 3.5965 - masked_accuracy: 0.4340\n","Epoch 1: masked_accuracy improved from 0.54837 to 0.55733, saving model to ./latest_2.weights.h5\n","\u001b[1m15999/19272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8:32\u001b[0m 157ms/step - loss: 3.5022 - masked_accuracy: 0.4420\n","Epoch 1: masked_accuracy improved from 0.55733 to 0.56560, saving model to ./latest_2.weights.h5\n","\u001b[1m16999/19272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5:55\u001b[0m 157ms/step - loss: 3.4152 - masked_accuracy: 0.4495\n","Epoch 1: masked_accuracy improved from 0.56560 to 0.57352, saving model to ./latest_2.weights.h5\n","\u001b[1m17999/19272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3:19\u001b[0m 156ms/step - loss: 3.3348 - masked_accuracy: 0.4566\n","Epoch 1: masked_accuracy improved from 0.57352 to 0.58097, saving model to ./latest_2.weights.h5\n","\u001b[1m18999/19272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 156ms/step - loss: 3.2599 - masked_accuracy: 0.4633\n","Epoch 1: masked_accuracy improved from 0.58097 to 0.58810, saving model to ./latest_2.weights.h5\n","\u001b[1m19272/19272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 3.2404 - masked_accuracy: 0.4651"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1717863834.616378     118 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","W0000 00:00:1717863850.057898     118 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m19272/19272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3489s\u001b[0m 169ms/step - loss: 3.2404 - masked_accuracy: 0.4651 - val_loss: 1.4043 - val_masked_accuracy: 0.6502\n","Epoch 2/5\n","\u001b[1m  727/19272\u001b[0m \u001b[37m\u001b[0m \u001b[1m47:41\u001b[0m 154ms/step - loss: 0.8988 - masked_accuracy: 0.7337\n","Epoch 2: masked_accuracy improved from 0.58810 to 0.73492, saving model to ./latest_2.weights.h5\n","\u001b[1m 1727/19272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m45:33\u001b[0m 156ms/step - loss: 0.8967 - masked_accuracy: 0.7348\n","Epoch 2: masked_accuracy improved from 0.73492 to 0.73653, saving model to ./latest_2.weights.h5\n","\u001b[1m 2727/19272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m43:00\u001b[0m 156ms/step - loss: 0.8932 - masked_accuracy: 0.7360\n","Epoch 2: masked_accuracy improved from 0.73653 to 0.73937, saving model to ./latest_2.weights.h5\n","\u001b[1m 3727/19272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m40:23\u001b[0m 156ms/step - loss: 0.8890 - masked_accuracy: 0.7372\n","Epoch 2: masked_accuracy improved from 0.73937 to 0.74224, saving model to ./latest_2.weights.h5\n","\u001b[1m 4727/19272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m37:48\u001b[0m 156ms/step - loss: 0.8846 - masked_accuracy: 0.7386\n","Epoch 2: masked_accuracy improved from 0.74224 to 0.74529, saving model to ./latest_2.weights.h5\n","\u001b[1m 5727/19272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m35:13\u001b[0m 156ms/step - loss: 0.8798 - masked_accuracy: 0.7400\n","Epoch 2: masked_accuracy improved from 0.74529 to 0.74818, saving model to ./latest_2.weights.h5\n","\u001b[1m 6727/19272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m32:38\u001b[0m 156ms/step - loss: 0.8750 - masked_accuracy: 0.7415\n","Epoch 2: masked_accuracy improved from 0.74818 to 0.75116, saving model to ./latest_2.weights.h5\n","\u001b[1m 7727/19272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m30:05\u001b[0m 156ms/step - loss: 0.8702 - masked_accuracy: 0.7429\n","Epoch 2: masked_accuracy improved from 0.75116 to 0.75400, saving model to ./latest_2.weights.h5\n","\u001b[1m 8727/19272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m27:29\u001b[0m 156ms/step - loss: 0.8652 - masked_accuracy: 0.7443\n","Epoch 2: masked_accuracy improved from 0.75400 to 0.75706, saving model to ./latest_2.weights.h5\n","\u001b[1m10727/19272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m22:17\u001b[0m 157ms/step - loss: 0.8553 - masked_accuracy: 0.7473\n","Epoch 2: masked_accuracy improved from 0.75995 to 0.76266, saving model to ./latest_2.weights.h5\n","\u001b[1m11727/19272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19:41\u001b[0m 157ms/step - loss: 0.8504 - masked_accuracy: 0.7487\n","Epoch 2: masked_accuracy improved from 0.76266 to 0.76547, saving model to ./latest_2.weights.h5\n","\u001b[1m12727/19272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17:04\u001b[0m 157ms/step - loss: 0.8455 - masked_accuracy: 0.7501\n","Epoch 2: masked_accuracy improved from 0.76547 to 0.76826, saving model to ./latest_2.weights.h5\n","\u001b[1m13727/19272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14:27\u001b[0m 156ms/step - loss: 0.8406 - masked_accuracy: 0.7515\n","Epoch 2: masked_accuracy improved from 0.76826 to 0.77100, saving model to ./latest_2.weights.h5\n","\u001b[1m14727/19272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11:51\u001b[0m 156ms/step - loss: 0.8358 - masked_accuracy: 0.7529\n","Epoch 2: masked_accuracy improved from 0.77100 to 0.77368, saving model to ./latest_2.weights.h5\n","\u001b[1m15727/19272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9:14\u001b[0m 156ms/step - loss: 0.8310 - masked_accuracy: 0.7544\n","Epoch 2: masked_accuracy improved from 0.77368 to 0.77628, saving model to ./latest_2.weights.h5\n","\u001b[1m16727/19272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6:38\u001b[0m 156ms/step - loss: 0.8263 - masked_accuracy: 0.7557\n","Epoch 2: masked_accuracy improved from 0.77628 to 0.77885, saving model to ./latest_2.weights.h5\n","\u001b[1m17727/19272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4:01\u001b[0m 156ms/step - loss: 0.8216 - masked_accuracy: 0.7571\n","Epoch 2: masked_accuracy improved from 0.77885 to 0.78140, saving model to ./latest_2.weights.h5\n","\u001b[1m18727/19272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1:25\u001b[0m 156ms/step - loss: 0.8169 - masked_accuracy: 0.7585\n","Epoch 2: masked_accuracy improved from 0.78140 to 0.78385, saving model to ./latest_2.weights.h5\n","\u001b[1m19272/19272\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3117s\u001b[0m 161ms/step - loss: 0.8144 - masked_accuracy: 0.7592 - val_loss: 1.5646 - val_masked_accuracy: 0.6664\n","Epoch 3/5\n","\u001b[1m  230/19272\u001b[0m \u001b[37m\u001b[0m \u001b[1m48:49\u001b[0m 154ms/step - loss: 0.5212 - masked_accuracy: 0.8438"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[162], line 19\u001b[0m\n\u001b[1;32m     10\u001b[0m checkpoint_filepath \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./latest_2.weights.h5\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     11\u001b[0m checkpoint_callback \u001b[38;5;241m=\u001b[39m ModelCheckpoint(\n\u001b[1;32m     12\u001b[0m     filepath\u001b[38;5;241m=\u001b[39mcheckpoint_filepath,\n\u001b[1;32m     13\u001b[0m     save_weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m                \u001b[38;5;66;03m# Verbosity level (optional)\u001b[39;00m\n\u001b[1;32m     18\u001b[0m )\n\u001b[0;32m---> 19\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mes\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:314\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    313\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 314\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    316\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:877\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    875\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 877\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    881\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    882\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["from keras.callbacks import EarlyStopping, ModelCheckpoint\n","\n","# Callbacks\n","es = EarlyStopping(monitor='val_masked_accuracy', mode='max', verbose=1, patience=2)\n","\n","epochs = 5\n","batch_size= 128\n","\n","checkpoint_filepath = '/content/drive/MyDrive/UNIBO_DEEP_LEARNING/latest.weights.h5'\n","checkpoint_filepath = './latest_2.weights.h5'\n","checkpoint_callback = ModelCheckpoint(\n","    filepath=checkpoint_filepath,\n","    save_weights_only=True, \n","    save_best_only=True,\n","    monitor='masked_accuracy',# Only save the weights\n","    save_freq=1000,          # Save every 1000 weight updates\n","    verbose=1                # Verbosity level (optional)\n",")\n","history = transformer.fit(\n","    (context_train, inputs_train),\n","    labels_train,\n","    epochs=epochs,\n","    batch_size=batch_size,\n","    callbacks=[checkpoint_callback, es],\n","    validation_data = ((context_val, inputs_val), labels_val)\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-08T14:33:26.040890Z","iopub.status.idle":"2024-06-08T14:33:26.041191Z","shell.execute_reply":"2024-06-08T14:33:26.041052Z","shell.execute_reply.started":"2024-06-08T14:33:26.041039Z"},"trusted":true},"outputs":[],"source":["transformer.summary()"]},{"cell_type":"code","execution_count":154,"metadata":{"execution":{"iopub.execute_input":"2024-06-08T15:13:39.948062Z","iopub.status.busy":"2024-06-08T15:13:39.947028Z","iopub.status.idle":"2024-06-08T15:13:39.973964Z","shell.execute_reply":"2024-06-08T15:13:39.972783Z","shell.execute_reply.started":"2024-06-08T15:13:39.948013Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["tf.Tensor(\n","[0.83297217 0.85873413 0.8852929  0.91267306 0.9409     0.97\n"," 0.97       0.9409     0.91267306 0.8852929  0.85873413 0.83297217\n"," 0.80798304 0.78374356 0.76023126 0.7374243  0.71530163 0.6938426\n"," 0.67302734 0.65283656 0.6332515  0.61425394 0.5958263  0.5779516\n"," 0.56061304 0.54379463 0.52748084 0.51165646], shape=(28,), dtype=float32)\n"]}],"source":["\n","\n","# Print the combined array\n","print(combined_array)\n"]},{"cell_type":"code","execution_count":166,"metadata":{"execution":{"iopub.execute_input":"2024-06-08T17:36:21.940908Z","iopub.status.busy":"2024-06-08T17:36:21.940506Z","iopub.status.idle":"2024-06-08T17:36:22.260096Z","shell.execute_reply":"2024-06-08T17:36:22.259164Z","shell.execute_reply.started":"2024-06-08T17:36:21.940877Z"},"trusted":true},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","\n","# Create a histogram\n","plt.hist(generated_scores, bins=20, alpha=0.7, color='blue')\n","\n","# Add title and labels\n","plt.title('Distribution of Double Numbers')\n","plt.xlabel('Value')\n","plt.ylabel('Frequency')\n","\n","# Show the plot\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-08T14:33:26.042709Z","iopub.status.idle":"2024-06-08T14:33:26.043011Z","shell.execute_reply":"2024-06-08T14:33:26.042874Z","shell.execute_reply.started":"2024-06-08T14:33:26.042861Z"},"trusted":true},"outputs":[],"source":["average_random_score, average_generated_score = get_average_score(x_train[2000:2100], y_train[2000:2100], transformer)\n","print(f'Average score on shuffled data: {average_random_score}')\n","print(f'Average score on generated data: {average_generated_score}')"]},{"cell_type":"code","execution_count":164,"metadata":{"execution":{"iopub.execute_input":"2024-06-08T17:19:21.494445Z","iopub.status.busy":"2024-06-08T17:19:21.494044Z","iopub.status.idle":"2024-06-08T17:35:06.965028Z","shell.execute_reply":"2024-06-08T17:35:06.964120Z","shell.execute_reply.started":"2024-06-08T17:19:21.494411Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["W0000 00:00:1717867182.235078     119 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["Average score on shuffled data: 0.1437748238947166\n","Average score on generated data: 0.488652290575781\n"]}],"source":["generated_scores, average_random_score, average_generated_score = get_average_score(x_test[2000:3000], y_test[2000:3000], transformer)\n","print(f'Average score on shuffled data: {average_random_score}')\n","print(f'Average score on generated data: {average_generated_score}')"]},{"cell_type":"code","execution_count":165,"metadata":{"execution":{"iopub.execute_input":"2024-06-08T17:35:07.013675Z","iopub.status.busy":"2024-06-08T17:35:07.013383Z","iopub.status.idle":"2024-06-08T17:35:07.100224Z","shell.execute_reply":"2024-06-08T17:35:07.099352Z","shell.execute_reply.started":"2024-06-08T17:35:07.013649Z"},"trusted":true},"outputs":[{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer_21\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mModel: \"transformer_21\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n","<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n","\n"," positional_embedding_34          ?                           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbedding</span>)                                                  \n","\n"," positional_embedding_35          ?                           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbedding</span>)                                                  \n","\n"," transformer_encoder_177          ?                             <span style=\"color: #00af00; text-decoration-color: #00af00\">198,272</span> \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)                                                   \n","\n"," transformer_encoder_178          ?                             <span style=\"color: #00af00; text-decoration-color: #00af00\">198,272</span> \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)                                                   \n","\n"," transformer_encoder_179          ?                             <span style=\"color: #00af00; text-decoration-color: #00af00\">198,272</span> \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)                                                   \n","\n"," transformer_encoder_180          ?                             <span style=\"color: #00af00; text-decoration-color: #00af00\">198,272</span> \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)                                                   \n","\n"," transformer_encoder_181          ?                             <span style=\"color: #00af00; text-decoration-color: #00af00\">198,272</span> \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)                                                   \n","\n"," transformer_encoder_182          ?                             <span style=\"color: #00af00; text-decoration-color: #00af00\">198,272</span> \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)                                                   \n","\n"," transformer_encoder_183          ?                             <span style=\"color: #00af00; text-decoration-color: #00af00\">198,272</span> \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)                                                   \n","\n"," transformer_encoder_184          ?                             <span style=\"color: #00af00; text-decoration-color: #00af00\">198,272</span> \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)                                                   \n","\n"," transformer_encoder_185          ?                             <span style=\"color: #00af00; text-decoration-color: #00af00\">198,272</span> \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)                                                   \n","\n"," transformer_encoder_186          ?                             <span style=\"color: #00af00; text-decoration-color: #00af00\">198,272</span> \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)                                                   \n","\n"," transformer_encoder_187          ?                             <span style=\"color: #00af00; text-decoration-color: #00af00\">198,272</span> \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)                                                   \n","\n"," transformer_encoder_188          ?                             <span style=\"color: #00af00; text-decoration-color: #00af00\">198,272</span> \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)                                                   \n","\n"," transformer_encoder_189          ?                             <span style=\"color: #00af00; text-decoration-color: #00af00\">198,272</span> \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)                                                   \n","\n"," transformer_encoder_190          ?                             <span style=\"color: #00af00; text-decoration-color: #00af00\">198,272</span> \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)                                                   \n","\n"," transformer_encoder_191          ?                             <span style=\"color: #00af00; text-decoration-color: #00af00\">198,272</span> \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)                                                   \n","\n"," transformer_encoder_192          ?                             <span style=\"color: #00af00; text-decoration-color: #00af00\">198,272</span> \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)                                                   \n","\n"," transformer_decoder_135          ?                             <span style=\"color: #00af00; text-decoration-color: #00af00\">264,576</span> \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoder</span>)                                                   \n","\n"," transformer_decoder_136          ?                             <span style=\"color: #00af00; text-decoration-color: #00af00\">264,576</span> \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoder</span>)                                                   \n","\n"," transformer_decoder_137          ?                             <span style=\"color: #00af00; text-decoration-color: #00af00\">264,576</span> \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoder</span>)                                                   \n","\n"," transformer_decoder_138          ?                             <span style=\"color: #00af00; text-decoration-color: #00af00\">264,576</span> \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoder</span>)                                                   \n","\n"," transformer_decoder_139          ?                             <span style=\"color: #00af00; text-decoration-color: #00af00\">264,576</span> \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoder</span>)                                                   \n","\n"," transformer_decoder_140          ?                             <span style=\"color: #00af00; text-decoration-color: #00af00\">264,576</span> \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoder</span>)                                                   \n","\n"," transformer_decoder_141          ?                             <span style=\"color: #00af00; text-decoration-color: #00af00\">264,576</span> \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoder</span>)                                                   \n","\n"," transformer_decoder_142          ?                             <span style=\"color: #00af00; text-decoration-color: #00af00\">264,576</span> \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoder</span>)                                                   \n","\n"," transformer_decoder_143          ?                             <span style=\"color: #00af00; text-decoration-color: #00af00\">264,576</span> \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoder</span>)                                                   \n","\n"," transformer_decoder_144          ?                             <span style=\"color: #00af00; text-decoration-color: #00af00\">264,576</span> \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoder</span>)                                                   \n","\n"," transformer_decoder_145          ?                             <span style=\"color: #00af00; text-decoration-color: #00af00\">264,576</span> \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoder</span>)                                                   \n","\n"," transformer_decoder_146          ?                             <span style=\"color: #00af00; text-decoration-color: #00af00\">264,576</span> \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoder</span>)                                                   \n","\n"," transformer_decoder_147          ?                             <span style=\"color: #00af00; text-decoration-color: #00af00\">264,576</span> \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoder</span>)                                                   \n","\n"," transformer_decoder_148          ?                             <span style=\"color: #00af00; text-decoration-color: #00af00\">264,576</span> \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoder</span>)                                                   \n","\n"," transformer_decoder_149          ?                             <span style=\"color: #00af00; text-decoration-color: #00af00\">264,576</span> \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoder</span>)                                                   \n","\n"," transformer_decoder_150          ?                             <span style=\"color: #00af00; text-decoration-color: #00af00\">264,576</span> \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoder</span>)                                                   \n","\n"," dense_221 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                ?                           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290,000</span> \n","\n","</pre>\n"],"text/plain":["\n","\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n","\n"," positional_embedding_34          ?                           \u001b[38;5;34m1,280,000\u001b[0m \n"," (\u001b[38;5;33mPositionalEmbedding\u001b[0m)                                                  \n","\n"," positional_embedding_35          ?                           \u001b[38;5;34m1,280,000\u001b[0m \n"," (\u001b[38;5;33mPositionalEmbedding\u001b[0m)                                                  \n","\n"," transformer_encoder_177          ?                             \u001b[38;5;34m198,272\u001b[0m \n"," (\u001b[38;5;33mTransformerEncoder\u001b[0m)                                                   \n","\n"," transformer_encoder_178          ?                             \u001b[38;5;34m198,272\u001b[0m \n"," (\u001b[38;5;33mTransformerEncoder\u001b[0m)                                                   \n","\n"," transformer_encoder_179          ?                             \u001b[38;5;34m198,272\u001b[0m \n"," (\u001b[38;5;33mTransformerEncoder\u001b[0m)                                                   \n","\n"," transformer_encoder_180          ?                             \u001b[38;5;34m198,272\u001b[0m \n"," (\u001b[38;5;33mTransformerEncoder\u001b[0m)                                                   \n","\n"," transformer_encoder_181          ?                             \u001b[38;5;34m198,272\u001b[0m \n"," (\u001b[38;5;33mTransformerEncoder\u001b[0m)                                                   \n","\n"," transformer_encoder_182          ?                             \u001b[38;5;34m198,272\u001b[0m \n"," (\u001b[38;5;33mTransformerEncoder\u001b[0m)                                                   \n","\n"," transformer_encoder_183          ?                             \u001b[38;5;34m198,272\u001b[0m \n"," (\u001b[38;5;33mTransformerEncoder\u001b[0m)                                                   \n","\n"," transformer_encoder_184          ?                             \u001b[38;5;34m198,272\u001b[0m \n"," (\u001b[38;5;33mTransformerEncoder\u001b[0m)                                                   \n","\n"," transformer_encoder_185          ?                             \u001b[38;5;34m198,272\u001b[0m \n"," (\u001b[38;5;33mTransformerEncoder\u001b[0m)                                                   \n","\n"," transformer_encoder_186          ?                             \u001b[38;5;34m198,272\u001b[0m \n"," (\u001b[38;5;33mTransformerEncoder\u001b[0m)                                                   \n","\n"," transformer_encoder_187          ?                             \u001b[38;5;34m198,272\u001b[0m \n"," (\u001b[38;5;33mTransformerEncoder\u001b[0m)                                                   \n","\n"," transformer_encoder_188          ?                             \u001b[38;5;34m198,272\u001b[0m \n"," (\u001b[38;5;33mTransformerEncoder\u001b[0m)                                                   \n","\n"," transformer_encoder_189          ?                             \u001b[38;5;34m198,272\u001b[0m \n"," (\u001b[38;5;33mTransformerEncoder\u001b[0m)                                                   \n","\n"," transformer_encoder_190          ?                             \u001b[38;5;34m198,272\u001b[0m \n"," (\u001b[38;5;33mTransformerEncoder\u001b[0m)                                                   \n","\n"," transformer_encoder_191          ?                             \u001b[38;5;34m198,272\u001b[0m \n"," (\u001b[38;5;33mTransformerEncoder\u001b[0m)                                                   \n","\n"," transformer_encoder_192          ?                             \u001b[38;5;34m198,272\u001b[0m \n"," (\u001b[38;5;33mTransformerEncoder\u001b[0m)                                                   \n","\n"," transformer_decoder_135          ?                             \u001b[38;5;34m264,576\u001b[0m \n"," (\u001b[38;5;33mTransformerDecoder\u001b[0m)                                                   \n","\n"," transformer_decoder_136          ?                             \u001b[38;5;34m264,576\u001b[0m \n"," (\u001b[38;5;33mTransformerDecoder\u001b[0m)                                                   \n","\n"," transformer_decoder_137          ?                             \u001b[38;5;34m264,576\u001b[0m \n"," (\u001b[38;5;33mTransformerDecoder\u001b[0m)                                                   \n","\n"," transformer_decoder_138          ?                             \u001b[38;5;34m264,576\u001b[0m \n"," (\u001b[38;5;33mTransformerDecoder\u001b[0m)                                                   \n","\n"," transformer_decoder_139          ?                             \u001b[38;5;34m264,576\u001b[0m \n"," (\u001b[38;5;33mTransformerDecoder\u001b[0m)                                                   \n","\n"," transformer_decoder_140          ?                             \u001b[38;5;34m264,576\u001b[0m \n"," (\u001b[38;5;33mTransformerDecoder\u001b[0m)                                                   \n","\n"," transformer_decoder_141          ?                             \u001b[38;5;34m264,576\u001b[0m \n"," (\u001b[38;5;33mTransformerDecoder\u001b[0m)                                                   \n","\n"," transformer_decoder_142          ?                             \u001b[38;5;34m264,576\u001b[0m \n"," (\u001b[38;5;33mTransformerDecoder\u001b[0m)                                                   \n","\n"," transformer_decoder_143          ?                             \u001b[38;5;34m264,576\u001b[0m \n"," (\u001b[38;5;33mTransformerDecoder\u001b[0m)                                                   \n","\n"," transformer_decoder_144          ?                             \u001b[38;5;34m264,576\u001b[0m \n"," (\u001b[38;5;33mTransformerDecoder\u001b[0m)                                                   \n","\n"," transformer_decoder_145          ?                             \u001b[38;5;34m264,576\u001b[0m \n"," (\u001b[38;5;33mTransformerDecoder\u001b[0m)                                                   \n","\n"," transformer_decoder_146          ?                             \u001b[38;5;34m264,576\u001b[0m \n"," (\u001b[38;5;33mTransformerDecoder\u001b[0m)                                                   \n","\n"," transformer_decoder_147          ?                             \u001b[38;5;34m264,576\u001b[0m \n"," (\u001b[38;5;33mTransformerDecoder\u001b[0m)                                                   \n","\n"," transformer_decoder_148          ?                             \u001b[38;5;34m264,576\u001b[0m \n"," (\u001b[38;5;33mTransformerDecoder\u001b[0m)                                                   \n","\n"," transformer_decoder_149          ?                             \u001b[38;5;34m264,576\u001b[0m \n"," (\u001b[38;5;33mTransformerDecoder\u001b[0m)                                                   \n","\n"," transformer_decoder_150          ?                             \u001b[38;5;34m264,576\u001b[0m \n"," (\u001b[38;5;33mTransformerDecoder\u001b[0m)                                                   \n","\n"," dense_221 (\u001b[38;5;33mDense\u001b[0m)                ?                           \u001b[38;5;34m1,290,000\u001b[0m \n","\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">33,766,705</span> (128.81 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m33,766,705\u001b[0m (128.81 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,255,568</span> (42.94 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,255,568\u001b[0m (42.94 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,511,137</span> (85.87 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m22,511,137\u001b[0m (85.87 MB)\n"]},"metadata":{},"output_type":"display_data"}],"source":["transformer.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-08T14:33:26.044917Z","iopub.status.idle":"2024-06-08T14:33:26.045215Z","shell.execute_reply":"2024-06-08T14:33:26.045079Z","shell.execute_reply.started":"2024-06-08T14:33:26.045066Z"},"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","\n","# Create a histogram\n","plt.hist(generated_scores, bins=20, alpha=0.7, color='blue')\n","\n","# Add title and labels\n","plt.title('Distribution of Double Numbers')\n","plt.xlabel('Value')\n","plt.ylabel('Frequency')\n","\n","# Show the plot\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-08T14:33:26.046518Z","iopub.status.idle":"2024-06-08T14:33:26.046828Z","shell.execute_reply":"2024-06-08T14:33:26.046690Z","shell.execute_reply.started":"2024-06-08T14:33:26.046678Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","\n","# Assuming you have an array of double numbers\n","original_array = np.random.normal(loc=0, scale=1, size=10000)  # Example array\n","\n","# Generate 5000 random indices within the range of the original array length\n","random_indices = np.random.choice(len(original_array), size=5000, replace=False)\n","\n","# Get the elements at these random indices\n","random_elements = original_array[random_indices]\n","\n","# Print the random indices and the corresponding elements\n","print(\"Random Indices:\", random_indices)\n","print(\"Random Elements:\", random_elements)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-08T14:33:26.048366Z","iopub.status.idle":"2024-06-08T14:33:26.048710Z","shell.execute_reply":"2024-06-08T14:33:26.048554Z","shell.execute_reply.started":"2024-06-08T14:33:26.048539Z"},"trusted":true},"outputs":[],"source":["def generate_prediction2(shuffled, model):\n","    max_count = sum(shuffled > 3)\n","    generated = pad_sequences(np.array([shuffled[:1]]), maxlen=28, padding='post')[0]\n","    available_tokens = shuffled[1:sum((shuffled>0))-1].tolist()\n","    context = pad_sequences(np.array([shuffled[1:]]), maxlen=28, padding='post')[0]\n","    for count in range(max_count):\n","        prediction = model.predict((np.array([context]), np.array([generated])), verbose=0) \n","        relevant_logits = prediction[0, count, available_tokens]\n","        generated_index = np.argmax(relevant_logits, axis=-1)\n","        generated_token = generated_index\n","        generated_token = available_tokens[generated_index]\n","#         available_tokens.remove(generated_token)\n","        generated[count+1] = generated_token\n","    \n","    generated[sum(generated>0)] = 2\n","    return generated[:sum(generated>0)]\n","def get_average_score2(x, y, model):\n","    num_examples = len(x)\n","    rs = []\n","    gs = []\n","    for i in range(num_examples):\n","        shuffled = x[i][:sum(x[i]>0)]\n","        ordered = y[i][:sum(y[i]>0)]\n","\n","        rs.append(score(ordered, shuffled))\n","        gs.append(score(ordered, generate_prediction2(x[i],model)))\n","        print(f'{i+1}.Random: {rs[-1]}')\n","        print(f'{i+1}.Generated: {gs[-1]}')\n","\n","    return gs, sum(rs)/num_examples, sum(gs)/num_examples"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-08T14:33:26.049813Z","iopub.status.idle":"2024-06-08T14:33:26.050119Z","shell.execute_reply":"2024-06-08T14:33:26.049975Z","shell.execute_reply.started":"2024-06-08T14:33:26.049962Z"},"trusted":true},"outputs":[],"source":["generated_scores, average_random_score, average_generated_score = get_average_score2(x_test[2000:3000], y_test[2000:3000], transformer)\n","print(f'Average score on shuffled data: {average_random_score}')\n","print(f'Average score on generated data: {average_generated_score}')"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30733,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
